{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "HARSIT AGRAWAL \n",
      "\n",
      "D A T A   A N A L Y T I C S   E N T H U S I A S T |\n",
      "D A T A   S P E C I A L I S T  \n",
      " \n",
      "\n",
      " \n",
      "\n",
      "  9084713325 \n",
      "  harsitagrawal59@gmail.com \n",
      "  Aligarh, U.P., India \n",
      "  linkedin.com/in/harsit59/ \n",
      "  harsitagrawal59@outlook.com \n",
      "  hackerrank.com/harsitagrawal59  \n",
      "\n",
      " \n",
      "\n",
      "  A B O U T   M E  \n",
      " \n",
      "\n",
      "  Actively looking for a job role in the field of data analytics and data \n",
      " \n",
      "\n",
      "specialization and other data driven jobs that match to the \n",
      "portfolio I have created and skills I have developed so far. \n",
      "\n",
      " \n",
      "\n",
      "S K I L L S  \n",
      "\n",
      "  E X P E R I E N C E  \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "7 / 10 \n",
      "SQL \n",
      "\n",
      "8 / 10 \n",
      "Microsoft Excel \n",
      " \n",
      "6 / 10 \n",
      "Python \n",
      "\n",
      "• \n",
      "\n",
      "INTERN \n",
      "\n",
      "           Kraft Heinz Pvt. Ltd. (June 2018) \n",
      "           Worked as a trainee over the  ongoing maintenance tasks that  were being carried in the  \n",
      "         organization. \n",
      " \n",
      " \n",
      "P R O J E C T S  \n",
      "\n",
      " \n",
      "\n",
      "• \n",
      "\n",
      "IICDC’19 (August 2019 — December 2019)  \n",
      "\n",
      " \n",
      "O T H E R   S K I L L S  \n",
      "\n",
      "•  Tableau \n",
      "•  Statistics \n",
      "•  Microsoft Office \n",
      "•  Solid Works \n",
      "•  AutoCAD \n",
      "\n",
      " \n",
      "\n",
      "E D U C A T I O N  \n",
      "\n",
      "BTech | Mechanical Engineering  \n",
      "Z.H. College of Engineering and Technology, \n",
      "A.M.U. 2017-2021 \n",
      "\n",
      "L A N G U A G E S  \n",
      "\n",
      "•  English \n",
      "•  Urdu \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "           Led the team of 5 through the quarter finals and worked out the business report of a    \n",
      "           device for specially aided(blind) people to be able to move around independently. The  \n",
      "           product has already been selected by the college tinkering lab and have been assured of  \n",
      "           all the aid for the research and development of the product. \n",
      "  \n",
      "\n",
      "•  HUMANOID (August 2019) \n",
      "\n",
      "            Designed a humanoid working as designer in a team  developing a robot  for basic \n",
      "         tasking. The project is still under development by the computer  science  \n",
      "              undergraduates, proficient in machine learning and artificial intelligence. \n",
      " \n",
      "\n",
      "•   ABU ROBOCON’19 #ZEPHYR3.0 (October 2018 — June 2019) \n",
      "        Worked as a fabricator along with other  14 team  members.  Achieved AIR 12 at the  \n",
      "        semifinals and AIR 25 at the finals held at IIT’D among  the other  81 teams  from all over  \n",
      "            India including IITs and NITs. \n",
      " \n",
      " \n",
      "C O  U R S  E S \n",
      "\n",
      "IBM DATA SCIENCE PROFESSIONAL CERTIFICATE @COURSERA (ONGOING) \n",
      "\n",
      "• \n",
      "•  MASTER SQL FOR DATA SCIENCE @UDEMY \n",
      "•  EXCEL SKILLS FOR BUSINESS: ESSENTIALS @COURSERA \n",
      "•  SQL FOR DATA SCIENCE @COURSERA \n",
      " \n",
      "\n",
      "\f",
      "\n"
     ]
    }
   ],
   "source": [
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.pdfinterp import PDFPageInterpreter\n",
    "from pdfminer.pdfinterp import PDFResourceManager\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from io import StringIO\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with open(r'C:\\Users\\harsi\\Downloads\\0.pdf', 'rb') as fh:\n",
    "        for page in PDFPage.get_pages(fh, caching=True, check_extractable=True):\n",
    "            resource_manager = PDFResourceManager()\n",
    "            fake_file_handle = StringIO()\n",
    "            converter = TextConverter(\n",
    "                                resource_manager, \n",
    "                                fake_file_handle, \n",
    "                                codec='utf-8', \n",
    "                                laparams=LAParams()\n",
    "                        )\n",
    "            page_interpreter = PDFPageInterpreter(\n",
    "                                resource_manager, \n",
    "                                converter\n",
    "                            )\n",
    "            page_interpreter.process_page(page)\n",
    "            text = fake_file_handle.getvalue()\n",
    "            yield text\n",
    "            converter.close()\n",
    "            fake_file_handle.close()\n",
    "fake_file_handle = StringIO()\n",
    "text = fake_file_handle.getvalue()\n",
    "for page in extract_text_from_pdf(r'C:\\Users\\harsi\\Downloads\\0.pdf'):\n",
    "    text += ' ' + page\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "def extract_name(resume_text):\n",
    "    nlp_text = nlp(text)\n",
    "\n",
    "    pattern = [{'POS': 'PROPN'}, {'POS': 'PROPN'}]\n",
    "    \n",
    "    matcher.add('NAME', None, *pattern)\n",
    "    \n",
    "    matches = matcher(nlp_text)\n",
    "    \n",
    "    for match_id, start, end in matches:\n",
    "        span = nlp_text[start:end]\n",
    "        print(span.text)\n",
    "        return span.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
